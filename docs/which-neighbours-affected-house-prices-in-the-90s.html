<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>3.7 Which Neighbours Affected House Prices in the ’90s? | ML Case Studies</title>
  <meta name="description" content="Case studies for reproducibility, imputation, and interpretability" />
  <meta name="generator" content="bookdown 0.19 and GitBook 2.6.7" />

  <meta property="og:title" content="3.7 Which Neighbours Affected House Prices in the ’90s? | ML Case Studies" />
  <meta property="og:type" content="book" />
  
  <meta property="og:image" content="images/cover.png" />
  <meta property="og:description" content="Case studies for reproducibility, imputation, and interpretability" />
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="3.7 Which Neighbours Affected House Prices in the ’90s? | ML Case Studies" />
  
  <meta name="twitter:description" content="Case studies for reproducibility, imputation, and interpretability" />
  <meta name="twitter:image" content="images/cover.png" />



<meta name="date" content="2020-06-01" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="surpassing-black-box-models-performance-on-unbalanced-data-with-an-interpretable-one-using-advanced-feature-engineering.html"/>
<link rel="next" href="explainable-computer-vision-with-embeddings-and-knn-classifier.html"/>
<script src="libs/header-attrs/header-attrs.js"></script>
<script src="libs/jquery/jquery.min.js"></script>
<link href="libs/gitbook/css/style.css" rel="stylesheet" />
<link href="libs/gitbook/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook/css/plugin-clipboard.css" rel="stylesheet" />









<script src="libs/kePrint/kePrint.js"></script>



<link rel="stylesheet" href="css/style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./"><h3>ML Case Studies</h3></a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Preface</a>
<ul>
<li class="chapter" data-level="" data-path="technical-setup.html"><a href="technical-setup.html"><i class="fa fa-check"></i>Technical Setup</a></li>
</ul></li>
<li class="chapter" data-level="1" data-path="reproducibility.html"><a href="reproducibility.html"><i class="fa fa-check"></i><b>1</b> Reproducibility of scientific papers</a>
<ul>
<li class="chapter" data-level="1.1" data-path="title-of-the-article.html"><a href="title-of-the-article.html"><i class="fa fa-check"></i><b>1.1</b> Title of the article</a>
<ul>
<li class="chapter" data-level="1.1.1" data-path="title-of-the-article.html"><a href="title-of-the-article.html#abstract"><i class="fa fa-check"></i><b>1.1.1</b> Abstract</a></li>
<li class="chapter" data-level="1.1.2" data-path="title-of-the-article.html"><a href="title-of-the-article.html#introduction-and-motivation"><i class="fa fa-check"></i><b>1.1.2</b> Introduction and Motivation</a></li>
<li class="chapter" data-level="1.1.3" data-path="title-of-the-article.html"><a href="title-of-the-article.html#related-work"><i class="fa fa-check"></i><b>1.1.3</b> Related Work</a></li>
<li class="chapter" data-level="1.1.4" data-path="title-of-the-article.html"><a href="title-of-the-article.html#methodology"><i class="fa fa-check"></i><b>1.1.4</b> Methodology</a></li>
<li class="chapter" data-level="1.1.5" data-path="title-of-the-article.html"><a href="title-of-the-article.html#results"><i class="fa fa-check"></i><b>1.1.5</b> Results</a></li>
<li class="chapter" data-level="1.1.6" data-path="title-of-the-article.html"><a href="title-of-the-article.html#summary-and-conclusions"><i class="fa fa-check"></i><b>1.1.6</b> Summary and conclusions</a></li>
</ul></li>
<li class="chapter" data-level="1.2" data-path="how-to-measure-reproducibility-classification-of-problems-with-reproducing-scientific-papers.html"><a href="how-to-measure-reproducibility-classification-of-problems-with-reproducing-scientific-papers.html"><i class="fa fa-check"></i><b>1.2</b> How to measure reproducibility? Classification of problems with reproducing scientific papers</a>
<ul>
<li class="chapter" data-level="1.2.1" data-path="how-to-measure-reproducibility-classification-of-problems-with-reproducing-scientific-papers.html"><a href="how-to-measure-reproducibility-classification-of-problems-with-reproducing-scientific-papers.html#abstract-1"><i class="fa fa-check"></i><b>1.2.1</b> Abstract</a></li>
<li class="chapter" data-level="1.2.2" data-path="how-to-measure-reproducibility-classification-of-problems-with-reproducing-scientific-papers.html"><a href="how-to-measure-reproducibility-classification-of-problems-with-reproducing-scientific-papers.html#introduction"><i class="fa fa-check"></i><b>1.2.2</b> Introduction</a></li>
<li class="chapter" data-level="1.2.3" data-path="how-to-measure-reproducibility-classification-of-problems-with-reproducing-scientific-papers.html"><a href="how-to-measure-reproducibility-classification-of-problems-with-reproducing-scientific-papers.html#related-work-1"><i class="fa fa-check"></i><b>1.2.3</b> Related Work</a></li>
<li class="chapter" data-level="1.2.4" data-path="how-to-measure-reproducibility-classification-of-problems-with-reproducing-scientific-papers.html"><a href="how-to-measure-reproducibility-classification-of-problems-with-reproducing-scientific-papers.html#methodology-1"><i class="fa fa-check"></i><b>1.2.4</b> Methodology</a></li>
<li class="chapter" data-level="1.2.5" data-path="how-to-measure-reproducibility-classification-of-problems-with-reproducing-scientific-papers.html"><a href="how-to-measure-reproducibility-classification-of-problems-with-reproducing-scientific-papers.html#results-1"><i class="fa fa-check"></i><b>1.2.5</b> Results</a></li>
<li class="chapter" data-level="1.2.6" data-path="how-to-measure-reproducibility-classification-of-problems-with-reproducing-scientific-papers.html"><a href="how-to-measure-reproducibility-classification-of-problems-with-reproducing-scientific-papers.html#summary-and-conclusions-1"><i class="fa fa-check"></i><b>1.2.6</b> Summary and conclusions</a></li>
</ul></li>
<li class="chapter" data-level="1.3" data-path="aging-articles-how-time-affects-reproducibility-of-scientific-papers.html"><a href="aging-articles-how-time-affects-reproducibility-of-scientific-papers.html"><i class="fa fa-check"></i><b>1.3</b> Aging articles. How time affects reproducibility of scientific papers?</a>
<ul>
<li class="chapter" data-level="1.3.1" data-path="aging-articles-how-time-affects-reproducibility-of-scientific-papers.html"><a href="aging-articles-how-time-affects-reproducibility-of-scientific-papers.html#abstract-2"><i class="fa fa-check"></i><b>1.3.1</b> Abstract</a></li>
<li class="chapter" data-level="1.3.2" data-path="aging-articles-how-time-affects-reproducibility-of-scientific-papers.html"><a href="aging-articles-how-time-affects-reproducibility-of-scientific-papers.html#introduction-1"><i class="fa fa-check"></i><b>1.3.2</b> Introduction</a></li>
<li class="chapter" data-level="1.3.3" data-path="aging-articles-how-time-affects-reproducibility-of-scientific-papers.html"><a href="aging-articles-how-time-affects-reproducibility-of-scientific-papers.html#methodology-2"><i class="fa fa-check"></i><b>1.3.3</b> Methodology</a></li>
<li class="chapter" data-level="1.3.4" data-path="aging-articles-how-time-affects-reproducibility-of-scientific-papers.html"><a href="aging-articles-how-time-affects-reproducibility-of-scientific-papers.html#results-2"><i class="fa fa-check"></i><b>1.3.4</b> Results</a></li>
<li class="chapter" data-level="1.3.5" data-path="aging-articles-how-time-affects-reproducibility-of-scientific-papers.html"><a href="aging-articles-how-time-affects-reproducibility-of-scientific-papers.html#conclusions"><i class="fa fa-check"></i><b>1.3.5</b> Conclusions</a></li>
<li class="chapter" data-level="1.3.6" data-path="aging-articles-how-time-affects-reproducibility-of-scientific-papers.html"><a href="aging-articles-how-time-affects-reproducibility-of-scientific-papers.html#summary"><i class="fa fa-check"></i><b>1.3.6</b> Summary</a></li>
</ul></li>
<li class="chapter" data-level="1.4" data-path="ways-to-reproduce-articles-in-terms-of-release-date-and-magazine.html"><a href="ways-to-reproduce-articles-in-terms-of-release-date-and-magazine.html"><i class="fa fa-check"></i><b>1.4</b> Ways to reproduce articles in terms of release date and magazine</a>
<ul>
<li class="chapter" data-level="1.4.1" data-path="ways-to-reproduce-articles-in-terms-of-release-date-and-magazine.html"><a href="ways-to-reproduce-articles-in-terms-of-release-date-and-magazine.html#abstract-3"><i class="fa fa-check"></i><b>1.4.1</b> Abstract</a></li>
<li class="chapter" data-level="1.4.2" data-path="ways-to-reproduce-articles-in-terms-of-release-date-and-magazine.html"><a href="ways-to-reproduce-articles-in-terms-of-release-date-and-magazine.html#introduction-and-motivation-1"><i class="fa fa-check"></i><b>1.4.2</b> Introduction and Motivation</a></li>
<li class="chapter" data-level="1.4.3" data-path="ways-to-reproduce-articles-in-terms-of-release-date-and-magazine.html"><a href="ways-to-reproduce-articles-in-terms-of-release-date-and-magazine.html#related-work-2"><i class="fa fa-check"></i><b>1.4.3</b> Related Work</a></li>
<li class="chapter" data-level="1.4.4" data-path="ways-to-reproduce-articles-in-terms-of-release-date-and-magazine.html"><a href="ways-to-reproduce-articles-in-terms-of-release-date-and-magazine.html#methodology-3"><i class="fa fa-check"></i><b>1.4.4</b> Methodology</a></li>
<li class="chapter" data-level="1.4.5" data-path="ways-to-reproduce-articles-in-terms-of-release-date-and-magazine.html"><a href="ways-to-reproduce-articles-in-terms-of-release-date-and-magazine.html#results-3"><i class="fa fa-check"></i><b>1.4.5</b> Results</a></li>
<li class="chapter" data-level="1.4.6" data-path="ways-to-reproduce-articles-in-terms-of-release-date-and-magazine.html"><a href="ways-to-reproduce-articles-in-terms-of-release-date-and-magazine.html#summary-and-conclusions-2"><i class="fa fa-check"></i><b>1.4.6</b> Summary and conclusions</a></li>
</ul></li>
<li class="chapter" data-level="1.5" data-path="reproducibility-of-outdated-articles-about-up-to-date-r-packages.html"><a href="reproducibility-of-outdated-articles-about-up-to-date-r-packages.html"><i class="fa fa-check"></i><b>1.5</b> Reproducibility of outdated articles about up-to-date R packages</a>
<ul>
<li class="chapter" data-level="1.5.1" data-path="reproducibility-of-outdated-articles-about-up-to-date-r-packages.html"><a href="reproducibility-of-outdated-articles-about-up-to-date-r-packages.html#abstract-4"><i class="fa fa-check"></i><b>1.5.1</b> Abstract</a></li>
<li class="chapter" data-level="1.5.2" data-path="reproducibility-of-outdated-articles-about-up-to-date-r-packages.html"><a href="reproducibility-of-outdated-articles-about-up-to-date-r-packages.html#introduction-and-motivation-2"><i class="fa fa-check"></i><b>1.5.2</b> Introduction and Motivation</a></li>
<li class="chapter" data-level="1.5.3" data-path="reproducibility-of-outdated-articles-about-up-to-date-r-packages.html"><a href="reproducibility-of-outdated-articles-about-up-to-date-r-packages.html#related-work-3"><i class="fa fa-check"></i><b>1.5.3</b> Related Work</a></li>
<li class="chapter" data-level="1.5.4" data-path="reproducibility-of-outdated-articles-about-up-to-date-r-packages.html"><a href="reproducibility-of-outdated-articles-about-up-to-date-r-packages.html#methodology-4"><i class="fa fa-check"></i><b>1.5.4</b> Methodology</a></li>
<li class="chapter" data-level="1.5.5" data-path="reproducibility-of-outdated-articles-about-up-to-date-r-packages.html"><a href="reproducibility-of-outdated-articles-about-up-to-date-r-packages.html#results-4"><i class="fa fa-check"></i><b>1.5.5</b> Results</a></li>
<li class="chapter" data-level="1.5.6" data-path="reproducibility-of-outdated-articles-about-up-to-date-r-packages.html"><a href="reproducibility-of-outdated-articles-about-up-to-date-r-packages.html#summary-and-conclusions-3"><i class="fa fa-check"></i><b>1.5.6</b> Summary and conclusions</a></li>
</ul></li>
<li class="chapter" data-level="1.6" data-path="correlation-between-reproducibility-of-components-of-research-papers-and-their-purpose.html"><a href="correlation-between-reproducibility-of-components-of-research-papers-and-their-purpose.html"><i class="fa fa-check"></i><b>1.6</b> Correlation between reproducibility of components of research papers and their purpose</a>
<ul>
<li class="chapter" data-level="1.6.1" data-path="correlation-between-reproducibility-of-components-of-research-papers-and-their-purpose.html"><a href="correlation-between-reproducibility-of-components-of-research-papers-and-their-purpose.html#abstract-5"><i class="fa fa-check"></i><b>1.6.1</b> Abstract</a></li>
<li class="chapter" data-level="1.6.2" data-path="correlation-between-reproducibility-of-components-of-research-papers-and-their-purpose.html"><a href="correlation-between-reproducibility-of-components-of-research-papers-and-their-purpose.html#introduction-and-motivation-3"><i class="fa fa-check"></i><b>1.6.2</b> Introduction and Motivation</a></li>
<li class="chapter" data-level="1.6.3" data-path="correlation-between-reproducibility-of-components-of-research-papers-and-their-purpose.html"><a href="correlation-between-reproducibility-of-components-of-research-papers-and-their-purpose.html#related-work-4"><i class="fa fa-check"></i><b>1.6.3</b> Related Work</a></li>
<li class="chapter" data-level="1.6.4" data-path="correlation-between-reproducibility-of-components-of-research-papers-and-their-purpose.html"><a href="correlation-between-reproducibility-of-components-of-research-papers-and-their-purpose.html#methodology-5"><i class="fa fa-check"></i><b>1.6.4</b> Methodology</a></li>
<li class="chapter" data-level="1.6.5" data-path="correlation-between-reproducibility-of-components-of-research-papers-and-their-purpose.html"><a href="correlation-between-reproducibility-of-components-of-research-papers-and-their-purpose.html#results-5"><i class="fa fa-check"></i><b>1.6.5</b> Results</a></li>
<li class="chapter" data-level="1.6.6" data-path="correlation-between-reproducibility-of-components-of-research-papers-and-their-purpose.html"><a href="correlation-between-reproducibility-of-components-of-research-papers-and-their-purpose.html#summary-and-conclusions-4"><i class="fa fa-check"></i><b>1.6.6</b> Summary and conclusions</a></li>
</ul></li>
<li class="chapter" data-level="1.7" data-path="how-active-development-affects-reproducibility.html"><a href="how-active-development-affects-reproducibility.html"><i class="fa fa-check"></i><b>1.7</b> How active development affects reproducibility</a>
<ul>
<li class="chapter" data-level="1.7.1" data-path="how-active-development-affects-reproducibility.html"><a href="how-active-development-affects-reproducibility.html#abstract-6"><i class="fa fa-check"></i><b>1.7.1</b> Abstract</a></li>
<li class="chapter" data-level="1.7.2" data-path="how-active-development-affects-reproducibility.html"><a href="how-active-development-affects-reproducibility.html#introduction-and-motivation-4"><i class="fa fa-check"></i><b>1.7.2</b> Introduction and Motivation</a></li>
<li class="chapter" data-level="1.7.3" data-path="how-active-development-affects-reproducibility.html"><a href="how-active-development-affects-reproducibility.html#methodology-6"><i class="fa fa-check"></i><b>1.7.3</b> Methodology</a></li>
<li class="chapter" data-level="1.7.4" data-path="how-active-development-affects-reproducibility.html"><a href="how-active-development-affects-reproducibility.html#results-6"><i class="fa fa-check"></i><b>1.7.4</b> Results</a></li>
<li class="chapter" data-level="1.7.5" data-path="how-active-development-affects-reproducibility.html"><a href="how-active-development-affects-reproducibility.html#summary-and-conclusions-5"><i class="fa fa-check"></i><b>1.7.5</b> Summary and conclusions</a></li>
</ul></li>
<li class="chapter" data-level="1.8" data-path="reproducibility-differences-of-articles-published-in-various-journals-and-using-r-or-python-language.html"><a href="reproducibility-differences-of-articles-published-in-various-journals-and-using-r-or-python-language.html"><i class="fa fa-check"></i><b>1.8</b> Reproducibility differences of articles published in various journals and using R or Python language</a>
<ul>
<li class="chapter" data-level="1.8.1" data-path="reproducibility-differences-of-articles-published-in-various-journals-and-using-r-or-python-language.html"><a href="reproducibility-differences-of-articles-published-in-various-journals-and-using-r-or-python-language.html#abstract-7"><i class="fa fa-check"></i><b>1.8.1</b> Abstract</a></li>
<li class="chapter" data-level="1.8.2" data-path="reproducibility-differences-of-articles-published-in-various-journals-and-using-r-or-python-language.html"><a href="reproducibility-differences-of-articles-published-in-various-journals-and-using-r-or-python-language.html#introduction-and-motivation-5"><i class="fa fa-check"></i><b>1.8.2</b> Introduction and Motivation</a></li>
<li class="chapter" data-level="1.8.3" data-path="reproducibility-differences-of-articles-published-in-various-journals-and-using-r-or-python-language.html"><a href="reproducibility-differences-of-articles-published-in-various-journals-and-using-r-or-python-language.html#methodology-7"><i class="fa fa-check"></i><b>1.8.3</b> Methodology</a></li>
<li class="chapter" data-level="1.8.4" data-path="reproducibility-differences-of-articles-published-in-various-journals-and-using-r-or-python-language.html"><a href="reproducibility-differences-of-articles-published-in-various-journals-and-using-r-or-python-language.html#results-7"><i class="fa fa-check"></i><b>1.8.4</b> Results</a></li>
<li class="chapter" data-level="1.8.5" data-path="reproducibility-differences-of-articles-published-in-various-journals-and-using-r-or-python-language.html"><a href="reproducibility-differences-of-articles-published-in-various-journals-and-using-r-or-python-language.html#summary-and-conclusions-6"><i class="fa fa-check"></i><b>1.8.5</b> Summary and conclusions</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="2" data-path="imputation.html"><a href="imputation.html"><i class="fa fa-check"></i><b>2</b> Imputation</a>
<ul>
<li class="chapter" data-level="2.1" data-path="default-imputation-efficiency-comparision.html"><a href="default-imputation-efficiency-comparision.html"><i class="fa fa-check"></i><b>2.1</b> Default imputation efficiency comparision</a>
<ul>
<li class="chapter" data-level="2.1.1" data-path="default-imputation-efficiency-comparision.html"><a href="default-imputation-efficiency-comparision.html#abstract-8"><i class="fa fa-check"></i><b>2.1.1</b> Abstract</a></li>
<li class="chapter" data-level="2.1.2" data-path="default-imputation-efficiency-comparision.html"><a href="default-imputation-efficiency-comparision.html#introduction-and-motivation-6"><i class="fa fa-check"></i><b>2.1.2</b> Introduction and Motivation</a></li>
<li class="chapter" data-level="2.1.3" data-path="default-imputation-efficiency-comparision.html"><a href="default-imputation-efficiency-comparision.html#related-work-5"><i class="fa fa-check"></i><b>2.1.3</b> Related Work</a></li>
<li class="chapter" data-level="2.1.4" data-path="default-imputation-efficiency-comparision.html"><a href="default-imputation-efficiency-comparision.html#methodology-8"><i class="fa fa-check"></i><b>2.1.4</b> Methodology</a></li>
<li class="chapter" data-level="2.1.5" data-path="default-imputation-efficiency-comparision.html"><a href="default-imputation-efficiency-comparision.html#results-8"><i class="fa fa-check"></i><b>2.1.5</b> Results</a></li>
<li class="chapter" data-level="2.1.6" data-path="default-imputation-efficiency-comparision.html"><a href="default-imputation-efficiency-comparision.html#summary-and-conclusions-7"><i class="fa fa-check"></i><b>2.1.6</b> Summary and conclusions</a></li>
</ul></li>
<li class="chapter" data-level="2.2" data-path="comparison-of-performance-of-data-imputation-methods-in-the-context-of-their-impact-on-the-prediction-efficiency-of-classification-algorithms-.html"><a href="comparison-of-performance-of-data-imputation-methods-in-the-context-of-their-impact-on-the-prediction-efficiency-of-classification-algorithms-.html"><i class="fa fa-check"></i><b>2.2</b> Comparison of performance of data imputation methods in the context of their impact on the prediction efficiency of classification algorithms.</a>
<ul>
<li class="chapter" data-level="2.2.1" data-path="comparison-of-performance-of-data-imputation-methods-in-the-context-of-their-impact-on-the-prediction-efficiency-of-classification-algorithms-.html"><a href="comparison-of-performance-of-data-imputation-methods-in-the-context-of-their-impact-on-the-prediction-efficiency-of-classification-algorithms-.html#abstract-9"><i class="fa fa-check"></i><b>2.2.1</b> Abstract</a></li>
<li class="chapter" data-level="2.2.2" data-path="comparison-of-performance-of-data-imputation-methods-in-the-context-of-their-impact-on-the-prediction-efficiency-of-classification-algorithms-.html"><a href="comparison-of-performance-of-data-imputation-methods-in-the-context-of-their-impact-on-the-prediction-efficiency-of-classification-algorithms-.html#introduction-and-motivation-7"><i class="fa fa-check"></i><b>2.2.2</b> Introduction and Motivation</a></li>
<li class="chapter" data-level="2.2.3" data-path="comparison-of-performance-of-data-imputation-methods-in-the-context-of-their-impact-on-the-prediction-efficiency-of-classification-algorithms-.html"><a href="comparison-of-performance-of-data-imputation-methods-in-the-context-of-their-impact-on-the-prediction-efficiency-of-classification-algorithms-.html#related-work-6"><i class="fa fa-check"></i><b>2.2.3</b> Related Work</a></li>
<li class="chapter" data-level="2.2.4" data-path="comparison-of-performance-of-data-imputation-methods-in-the-context-of-their-impact-on-the-prediction-efficiency-of-classification-algorithms-.html"><a href="comparison-of-performance-of-data-imputation-methods-in-the-context-of-their-impact-on-the-prediction-efficiency-of-classification-algorithms-.html#methodology-9"><i class="fa fa-check"></i><b>2.2.4</b> Methodology</a></li>
<li class="chapter" data-level="2.2.5" data-path="comparison-of-performance-of-data-imputation-methods-in-the-context-of-their-impact-on-the-prediction-efficiency-of-classification-algorithms-.html"><a href="comparison-of-performance-of-data-imputation-methods-in-the-context-of-their-impact-on-the-prediction-efficiency-of-classification-algorithms-.html#results-9"><i class="fa fa-check"></i><b>2.2.5</b> Results</a></li>
<li class="chapter" data-level="2.2.6" data-path="comparison-of-performance-of-data-imputation-methods-in-the-context-of-their-impact-on-the-prediction-efficiency-of-classification-algorithms-.html"><a href="comparison-of-performance-of-data-imputation-methods-in-the-context-of-their-impact-on-the-prediction-efficiency-of-classification-algorithms-.html#summary-and-conclusions-8"><i class="fa fa-check"></i><b>2.2.6</b> Summary and conclusions</a></li>
</ul></li>
<li class="chapter" data-level="2.3" data-path="various-data-imputation-techniques-in-r.html"><a href="various-data-imputation-techniques-in-r.html"><i class="fa fa-check"></i><b>2.3</b> Various data imputation techniques in R</a>
<ul>
<li class="chapter" data-level="2.3.1" data-path="various-data-imputation-techniques-in-r.html"><a href="various-data-imputation-techniques-in-r.html#abstract-10"><i class="fa fa-check"></i><b>2.3.1</b> Abstract</a></li>
<li class="chapter" data-level="2.3.2" data-path="various-data-imputation-techniques-in-r.html"><a href="various-data-imputation-techniques-in-r.html#introduction-and-motivation-8"><i class="fa fa-check"></i><b>2.3.2</b> Introduction and Motivation</a></li>
<li class="chapter" data-level="2.3.3" data-path="various-data-imputation-techniques-in-r.html"><a href="various-data-imputation-techniques-in-r.html#methodology-10"><i class="fa fa-check"></i><b>2.3.3</b> Methodology</a></li>
<li class="chapter" data-level="2.3.4" data-path="various-data-imputation-techniques-in-r.html"><a href="various-data-imputation-techniques-in-r.html#results-10"><i class="fa fa-check"></i><b>2.3.4</b> Results</a></li>
<li class="chapter" data-level="2.3.5" data-path="various-data-imputation-techniques-in-r.html"><a href="various-data-imputation-techniques-in-r.html#summary-and-conclusions-9"><i class="fa fa-check"></i><b>2.3.5</b> Summary and conclusions</a></li>
</ul></li>
<li class="chapter" data-level="2.4" data-path="comparison-of-efficiency-of-various-data-imputation-techniques.html"><a href="comparison-of-efficiency-of-various-data-imputation-techniques.html"><i class="fa fa-check"></i><b>2.4</b> Comparison of efficiency of various data imputation techniques</a>
<ul>
<li class="chapter" data-level="2.4.1" data-path="comparison-of-efficiency-of-various-data-imputation-techniques.html"><a href="comparison-of-efficiency-of-various-data-imputation-techniques.html#abstract-11"><i class="fa fa-check"></i><b>2.4.1</b> Abstract</a></li>
<li class="chapter" data-level="2.4.2" data-path="comparison-of-efficiency-of-various-data-imputation-techniques.html"><a href="comparison-of-efficiency-of-various-data-imputation-techniques.html#introduction-and-motivation-9"><i class="fa fa-check"></i><b>2.4.2</b> Introduction and Motivation</a></li>
<li class="chapter" data-level="2.4.3" data-path="comparison-of-efficiency-of-various-data-imputation-techniques.html"><a href="comparison-of-efficiency-of-various-data-imputation-techniques.html#related-work-7"><i class="fa fa-check"></i><b>2.4.3</b> Related Work</a></li>
<li class="chapter" data-level="2.4.4" data-path="comparison-of-efficiency-of-various-data-imputation-techniques.html"><a href="comparison-of-efficiency-of-various-data-imputation-techniques.html#methodology-11"><i class="fa fa-check"></i><b>2.4.4</b> Methodology</a></li>
<li class="chapter" data-level="2.4.5" data-path="comparison-of-efficiency-of-various-data-imputation-techniques.html"><a href="comparison-of-efficiency-of-various-data-imputation-techniques.html#results-11"><i class="fa fa-check"></i><b>2.4.5</b> Results</a></li>
<li class="chapter" data-level="2.4.6" data-path="comparison-of-efficiency-of-various-data-imputation-techniques.html"><a href="comparison-of-efficiency-of-various-data-imputation-techniques.html#summary-and-conclusions-10"><i class="fa fa-check"></i><b>2.4.6</b> Summary and conclusions</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="3" data-path="interpretability.html"><a href="interpretability.html"><i class="fa fa-check"></i><b>3</b> Interpretability</a>
<ul>
<li class="chapter" data-level="3.1" data-path="building-an-explainable-model-for-ordinal-classification-on-eucalyptus-dataset-meeting-black-box-model-performance-levels-.html"><a href="building-an-explainable-model-for-ordinal-classification-on-eucalyptus-dataset-meeting-black-box-model-performance-levels-.html"><i class="fa fa-check"></i><b>3.1</b> Building an explainable model for ordinal classification on Eucalyptus dataset. Meeting black box model performance levels.</a>
<ul>
<li class="chapter" data-level="3.1.1" data-path="building-an-explainable-model-for-ordinal-classification-on-eucalyptus-dataset-meeting-black-box-model-performance-levels-.html"><a href="building-an-explainable-model-for-ordinal-classification-on-eucalyptus-dataset-meeting-black-box-model-performance-levels-.html#abstract-12"><i class="fa fa-check"></i><b>3.1.1</b> Abstract</a></li>
<li class="chapter" data-level="3.1.2" data-path="building-an-explainable-model-for-ordinal-classification-on-eucalyptus-dataset-meeting-black-box-model-performance-levels-.html"><a href="building-an-explainable-model-for-ordinal-classification-on-eucalyptus-dataset-meeting-black-box-model-performance-levels-.html#introduction-and-motivation-10"><i class="fa fa-check"></i><b>3.1.2</b> 1. Introduction and Motivation</a></li>
<li class="chapter" data-level="3.1.3" data-path="building-an-explainable-model-for-ordinal-classification-on-eucalyptus-dataset-meeting-black-box-model-performance-levels-.html"><a href="building-an-explainable-model-for-ordinal-classification-on-eucalyptus-dataset-meeting-black-box-model-performance-levels-.html#related-work-8"><i class="fa fa-check"></i><b>3.1.3</b> 2. Related Work</a></li>
<li class="chapter" data-level="3.1.4" data-path="building-an-explainable-model-for-ordinal-classification-on-eucalyptus-dataset-meeting-black-box-model-performance-levels-.html"><a href="building-an-explainable-model-for-ordinal-classification-on-eucalyptus-dataset-meeting-black-box-model-performance-levels-.html#methodology-12"><i class="fa fa-check"></i><b>3.1.4</b> 3. Methodology</a></li>
<li class="chapter" data-level="3.1.5" data-path="building-an-explainable-model-for-ordinal-classification-on-eucalyptus-dataset-meeting-black-box-model-performance-levels-.html"><a href="building-an-explainable-model-for-ordinal-classification-on-eucalyptus-dataset-meeting-black-box-model-performance-levels-.html#results-12"><i class="fa fa-check"></i><b>3.1.5</b> 4. Results</a></li>
<li class="chapter" data-level="3.1.6" data-path="building-an-explainable-model-for-ordinal-classification-on-eucalyptus-dataset-meeting-black-box-model-performance-levels-.html"><a href="building-an-explainable-model-for-ordinal-classification-on-eucalyptus-dataset-meeting-black-box-model-performance-levels-.html#model-explanantion"><i class="fa fa-check"></i><b>3.1.6</b> 5. Model explanantion</a></li>
<li class="chapter" data-level="3.1.7" data-path="building-an-explainable-model-for-ordinal-classification-on-eucalyptus-dataset-meeting-black-box-model-performance-levels-.html"><a href="building-an-explainable-model-for-ordinal-classification-on-eucalyptus-dataset-meeting-black-box-model-performance-levels-.html#summary-and-conclusions-11"><i class="fa fa-check"></i><b>3.1.7</b> 6. Summary and conclusions</a></li>
<li class="chapter" data-level="3.1.8" data-path="building-an-explainable-model-for-ordinal-classification-on-eucalyptus-dataset-meeting-black-box-model-performance-levels-.html"><a href="building-an-explainable-model-for-ordinal-classification-on-eucalyptus-dataset-meeting-black-box-model-performance-levels-.html#references"><i class="fa fa-check"></i><b>3.1.8</b> 7. References</a></li>
</ul></li>
<li class="chapter" data-level="3.2" data-path="predicting-code-defects-using-interpretable-static-measures-.html"><a href="predicting-code-defects-using-interpretable-static-measures-.html"><i class="fa fa-check"></i><b>3.2</b> Predicting code defects using interpretable static measures.</a>
<ul>
<li class="chapter" data-level="3.2.1" data-path="predicting-code-defects-using-interpretable-static-measures-.html"><a href="predicting-code-defects-using-interpretable-static-measures-.html#abstract-13"><i class="fa fa-check"></i><b>3.2.1</b> Abstract</a></li>
<li class="chapter" data-level="3.2.2" data-path="predicting-code-defects-using-interpretable-static-measures-.html"><a href="predicting-code-defects-using-interpretable-static-measures-.html#introduction-and-motivation-11"><i class="fa fa-check"></i><b>3.2.2</b> Introduction and Motivation</a></li>
<li class="chapter" data-level="3.2.3" data-path="predicting-code-defects-using-interpretable-static-measures-.html"><a href="predicting-code-defects-using-interpretable-static-measures-.html#dataset"><i class="fa fa-check"></i><b>3.2.3</b> Dataset</a></li>
<li class="chapter" data-level="3.2.4" data-path="predicting-code-defects-using-interpretable-static-measures-.html"><a href="predicting-code-defects-using-interpretable-static-measures-.html#methodology-13"><i class="fa fa-check"></i><b>3.2.4</b> Methodology</a></li>
<li class="chapter" data-level="3.2.5" data-path="predicting-code-defects-using-interpretable-static-measures-.html"><a href="predicting-code-defects-using-interpretable-static-measures-.html#results-13"><i class="fa fa-check"></i><b>3.2.5</b> Results</a></li>
<li class="chapter" data-level="3.2.6" data-path="predicting-code-defects-using-interpretable-static-measures-.html"><a href="predicting-code-defects-using-interpretable-static-measures-.html#summary-and-conclusions-12"><i class="fa fa-check"></i><b>3.2.6</b> Summary and conclusions</a></li>
</ul></li>
<li class="chapter" data-level="3.3" data-path="using-interpretable-machine-learning-models-in-the-higgs-boson-detection-.html"><a href="using-interpretable-machine-learning-models-in-the-higgs-boson-detection-.html"><i class="fa fa-check"></i><b>3.3</b> Using interpretable Machine Learning models in the Higgs boson detection.</a>
<ul>
<li class="chapter" data-level="3.3.1" data-path="using-interpretable-machine-learning-models-in-the-higgs-boson-detection-.html"><a href="using-interpretable-machine-learning-models-in-the-higgs-boson-detection-.html#abstract-14"><i class="fa fa-check"></i><b>3.3.1</b> Abstract</a></li>
<li class="chapter" data-level="3.3.2" data-path="using-interpretable-machine-learning-models-in-the-higgs-boson-detection-.html"><a href="using-interpretable-machine-learning-models-in-the-higgs-boson-detection-.html#introduction-and-motivation-12"><i class="fa fa-check"></i><b>3.3.2</b> Introduction and Motivation</a></li>
<li class="chapter" data-level="3.3.3" data-path="using-interpretable-machine-learning-models-in-the-higgs-boson-detection-.html"><a href="using-interpretable-machine-learning-models-in-the-higgs-boson-detection-.html#related-work-9"><i class="fa fa-check"></i><b>3.3.3</b> Related Work</a></li>
<li class="chapter" data-level="3.3.4" data-path="using-interpretable-machine-learning-models-in-the-higgs-boson-detection-.html"><a href="using-interpretable-machine-learning-models-in-the-higgs-boson-detection-.html#methodology-14"><i class="fa fa-check"></i><b>3.3.4</b> Methodology</a></li>
<li class="chapter" data-level="3.3.5" data-path="using-interpretable-machine-learning-models-in-the-higgs-boson-detection-.html"><a href="using-interpretable-machine-learning-models-in-the-higgs-boson-detection-.html#results-14"><i class="fa fa-check"></i><b>3.3.5</b> Results</a></li>
<li class="chapter" data-level="3.3.6" data-path="using-interpretable-machine-learning-models-in-the-higgs-boson-detection-.html"><a href="using-interpretable-machine-learning-models-in-the-higgs-boson-detection-.html#summary-and-conclusions-13"><i class="fa fa-check"></i><b>3.3.6</b> Summary and conclusions</a></li>
</ul></li>
<li class="chapter" data-level="3.4" data-path="can-automated-regression-beat-linear-model.html"><a href="can-automated-regression-beat-linear-model.html"><i class="fa fa-check"></i><b>3.4</b> Can Automated Regression beat linear model?</a>
<ul>
<li class="chapter" data-level="3.4.1" data-path="can-automated-regression-beat-linear-model.html"><a href="can-automated-regression-beat-linear-model.html#abstract-15"><i class="fa fa-check"></i><b>3.4.1</b> Abstract</a></li>
<li class="chapter" data-level="3.4.2" data-path="can-automated-regression-beat-linear-model.html"><a href="can-automated-regression-beat-linear-model.html#introduction-and-motivation-13"><i class="fa fa-check"></i><b>3.4.2</b> Introduction and Motivation</a></li>
<li class="chapter" data-level="3.4.3" data-path="can-automated-regression-beat-linear-model.html"><a href="can-automated-regression-beat-linear-model.html#data-1"><i class="fa fa-check"></i><b>3.4.3</b> Data</a></li>
<li class="chapter" data-level="3.4.4" data-path="can-automated-regression-beat-linear-model.html"><a href="can-automated-regression-beat-linear-model.html#methodology-15"><i class="fa fa-check"></i><b>3.4.4</b> Methodology</a></li>
<li class="chapter" data-level="3.4.5" data-path="can-automated-regression-beat-linear-model.html"><a href="can-automated-regression-beat-linear-model.html#results-15"><i class="fa fa-check"></i><b>3.4.5</b> Results</a></li>
<li class="chapter" data-level="3.4.6" data-path="can-automated-regression-beat-linear-model.html"><a href="can-automated-regression-beat-linear-model.html#summary-and-conclusions-14"><i class="fa fa-check"></i><b>3.4.6</b> Summary and conclusions</a></li>
</ul></li>
<li class="chapter" data-level="3.5" data-path="interpretable-non-linear-feature-engineering-techniques-for-linear-regression-models-exploration-on-concrete-compressive-strength-dataset-with-a-new-feature-importance-metric-.html"><a href="interpretable-non-linear-feature-engineering-techniques-for-linear-regression-models-exploration-on-concrete-compressive-strength-dataset-with-a-new-feature-importance-metric-.html"><i class="fa fa-check"></i><b>3.5</b> Interpretable, non-linear feature engineering techniques for linear regression models - exploration on concrete compressive strength dataset with a new feature importance metric.</a>
<ul>
<li class="chapter" data-level="3.5.1" data-path="interpretable-non-linear-feature-engineering-techniques-for-linear-regression-models-exploration-on-concrete-compressive-strength-dataset-with-a-new-feature-importance-metric-.html"><a href="interpretable-non-linear-feature-engineering-techniques-for-linear-regression-models-exploration-on-concrete-compressive-strength-dataset-with-a-new-feature-importance-metric-.html#abstract-16"><i class="fa fa-check"></i><b>3.5.1</b> Abstract</a></li>
<li class="chapter" data-level="3.5.2" data-path="interpretable-non-linear-feature-engineering-techniques-for-linear-regression-models-exploration-on-concrete-compressive-strength-dataset-with-a-new-feature-importance-metric-.html"><a href="interpretable-non-linear-feature-engineering-techniques-for-linear-regression-models-exploration-on-concrete-compressive-strength-dataset-with-a-new-feature-importance-metric-.html#introduction-and-motivation-14"><i class="fa fa-check"></i><b>3.5.2</b> Introduction and Motivation</a></li>
<li class="chapter" data-level="3.5.3" data-path="interpretable-non-linear-feature-engineering-techniques-for-linear-regression-models-exploration-on-concrete-compressive-strength-dataset-with-a-new-feature-importance-metric-.html"><a href="interpretable-non-linear-feature-engineering-techniques-for-linear-regression-models-exploration-on-concrete-compressive-strength-dataset-with-a-new-feature-importance-metric-.html#related-work-10"><i class="fa fa-check"></i><b>3.5.3</b> Related Work</a></li>
<li class="chapter" data-level="3.5.4" data-path="interpretable-non-linear-feature-engineering-techniques-for-linear-regression-models-exploration-on-concrete-compressive-strength-dataset-with-a-new-feature-importance-metric-.html"><a href="interpretable-non-linear-feature-engineering-techniques-for-linear-regression-models-exploration-on-concrete-compressive-strength-dataset-with-a-new-feature-importance-metric-.html#methodology-16"><i class="fa fa-check"></i><b>3.5.4</b> Methodology</a></li>
<li class="chapter" data-level="3.5.5" data-path="interpretable-non-linear-feature-engineering-techniques-for-linear-regression-models-exploration-on-concrete-compressive-strength-dataset-with-a-new-feature-importance-metric-.html"><a href="interpretable-non-linear-feature-engineering-techniques-for-linear-regression-models-exploration-on-concrete-compressive-strength-dataset-with-a-new-feature-importance-metric-.html#results-16"><i class="fa fa-check"></i><b>3.5.5</b> Results</a></li>
<li class="chapter" data-level="3.5.6" data-path="interpretable-non-linear-feature-engineering-techniques-for-linear-regression-models-exploration-on-concrete-compressive-strength-dataset-with-a-new-feature-importance-metric-.html"><a href="interpretable-non-linear-feature-engineering-techniques-for-linear-regression-models-exploration-on-concrete-compressive-strength-dataset-with-a-new-feature-importance-metric-.html#summary-and-conclusions-15"><i class="fa fa-check"></i><b>3.5.6</b> Summary and conclusions</a></li>
</ul></li>
<li class="chapter" data-level="3.6" data-path="surpassing-black-box-models-performance-on-unbalanced-data-with-an-interpretable-one-using-advanced-feature-engineering.html"><a href="surpassing-black-box-models-performance-on-unbalanced-data-with-an-interpretable-one-using-advanced-feature-engineering.html"><i class="fa fa-check"></i><b>3.6</b> Surpassing black box model’s performance on unbalanced data with an interpretable one using advanced feature engineering</a>
<ul>
<li class="chapter" data-level="3.6.1" data-path="surpassing-black-box-models-performance-on-unbalanced-data-with-an-interpretable-one-using-advanced-feature-engineering.html"><a href="surpassing-black-box-models-performance-on-unbalanced-data-with-an-interpretable-one-using-advanced-feature-engineering.html#abstract-17"><i class="fa fa-check"></i><b>3.6.1</b> Abstract</a></li>
<li class="chapter" data-level="3.6.2" data-path="surpassing-black-box-models-performance-on-unbalanced-data-with-an-interpretable-one-using-advanced-feature-engineering.html"><a href="surpassing-black-box-models-performance-on-unbalanced-data-with-an-interpretable-one-using-advanced-feature-engineering.html#introduction-and-motivation-15"><i class="fa fa-check"></i><b>3.6.2</b> Introduction and Motivation</a></li>
<li class="chapter" data-level="3.6.3" data-path="surpassing-black-box-models-performance-on-unbalanced-data-with-an-interpretable-one-using-advanced-feature-engineering.html"><a href="surpassing-black-box-models-performance-on-unbalanced-data-with-an-interpretable-one-using-advanced-feature-engineering.html#data-2"><i class="fa fa-check"></i><b>3.6.3</b> Data</a></li>
<li class="chapter" data-level="3.6.4" data-path="surpassing-black-box-models-performance-on-unbalanced-data-with-an-interpretable-one-using-advanced-feature-engineering.html"><a href="surpassing-black-box-models-performance-on-unbalanced-data-with-an-interpretable-one-using-advanced-feature-engineering.html#related-work-11"><i class="fa fa-check"></i><b>3.6.4</b> Related work</a></li>
<li class="chapter" data-level="3.6.5" data-path="surpassing-black-box-models-performance-on-unbalanced-data-with-an-interpretable-one-using-advanced-feature-engineering.html"><a href="surpassing-black-box-models-performance-on-unbalanced-data-with-an-interpretable-one-using-advanced-feature-engineering.html#methodology-17"><i class="fa fa-check"></i><b>3.6.5</b> Methodology</a></li>
</ul></li>
<li class="chapter" data-level="3.7" data-path="which-neighbours-affected-house-prices-in-the-90s.html"><a href="which-neighbours-affected-house-prices-in-the-90s.html"><i class="fa fa-check"></i><b>3.7</b> Which Neighbours Affected House Prices in the ’90s?</a>
<ul>
<li class="chapter" data-level="3.7.1" data-path="which-neighbours-affected-house-prices-in-the-90s.html"><a href="which-neighbours-affected-house-prices-in-the-90s.html#abstract-18"><i class="fa fa-check"></i><b>3.7.1</b> Abstract</a></li>
<li class="chapter" data-level="3.7.2" data-path="which-neighbours-affected-house-prices-in-the-90s.html"><a href="which-neighbours-affected-house-prices-in-the-90s.html#introduction-2"><i class="fa fa-check"></i><b>3.7.2</b> Introduction</a></li>
<li class="chapter" data-level="3.7.3" data-path="which-neighbours-affected-house-prices-in-the-90s.html"><a href="which-neighbours-affected-house-prices-in-the-90s.html#related-work-12"><i class="fa fa-check"></i><b>3.7.3</b> Related Work</a></li>
<li class="chapter" data-level="3.7.4" data-path="which-neighbours-affected-house-prices-in-the-90s.html"><a href="which-neighbours-affected-house-prices-in-the-90s.html#data-3"><i class="fa fa-check"></i><b>3.7.4</b> Data</a></li>
<li class="chapter" data-level="3.7.5" data-path="which-neighbours-affected-house-prices-in-the-90s.html"><a href="which-neighbours-affected-house-prices-in-the-90s.html#methodology-18"><i class="fa fa-check"></i><b>3.7.5</b> Methodology</a></li>
<li class="chapter" data-level="3.7.6" data-path="which-neighbours-affected-house-prices-in-the-90s.html"><a href="which-neighbours-affected-house-prices-in-the-90s.html#results-17"><i class="fa fa-check"></i><b>3.7.6</b> Results</a></li>
<li class="chapter" data-level="3.7.7" data-path="which-neighbours-affected-house-prices-in-the-90s.html"><a href="which-neighbours-affected-house-prices-in-the-90s.html#conclusions-1"><i class="fa fa-check"></i><b>3.7.7</b> Conclusions</a></li>
</ul></li>
<li class="chapter" data-level="3.8" data-path="explainable-computer-vision-with-embeddings-and-knn-classifier.html"><a href="explainable-computer-vision-with-embeddings-and-knn-classifier.html"><i class="fa fa-check"></i><b>3.8</b> Explainable Computer Vision with embeddings and KNN classifier</a>
<ul>
<li class="chapter" data-level="3.8.1" data-path="explainable-computer-vision-with-embeddings-and-knn-classifier.html"><a href="explainable-computer-vision-with-embeddings-and-knn-classifier.html#abstract-19"><i class="fa fa-check"></i><b>3.8.1</b> Abstract</a></li>
<li class="chapter" data-level="3.8.2" data-path="explainable-computer-vision-with-embeddings-and-knn-classifier.html"><a href="explainable-computer-vision-with-embeddings-and-knn-classifier.html#introduction-3"><i class="fa fa-check"></i><b>3.8.2</b> 3.8.1 Introduction</a></li>
<li class="chapter" data-level="3.8.3" data-path="explainable-computer-vision-with-embeddings-and-knn-classifier.html"><a href="explainable-computer-vision-with-embeddings-and-knn-classifier.html#data-4"><i class="fa fa-check"></i><b>3.8.3</b> 3.8.2 Data</a></li>
<li class="chapter" data-level="3.8.4" data-path="explainable-computer-vision-with-embeddings-and-knn-classifier.html"><a href="explainable-computer-vision-with-embeddings-and-knn-classifier.html#methodology-19"><i class="fa fa-check"></i><b>3.8.4</b> 3.8.3 Methodology</a></li>
<li class="chapter" data-level="3.8.5" data-path="explainable-computer-vision-with-embeddings-and-knn-classifier.html"><a href="explainable-computer-vision-with-embeddings-and-knn-classifier.html#standard-intepretable-models"><i class="fa fa-check"></i><b>3.8.5</b> 3.8.4 Standard Intepretable Models</a></li>
<li class="chapter" data-level="3.8.6" data-path="explainable-computer-vision-with-embeddings-and-knn-classifier.html"><a href="explainable-computer-vision-with-embeddings-and-knn-classifier.html#our-approach"><i class="fa fa-check"></i><b>3.8.6</b> 3.8.5 Our Approach</a></li>
<li class="chapter" data-level="3.8.7" data-path="explainable-computer-vision-with-embeddings-and-knn-classifier.html"><a href="explainable-computer-vision-with-embeddings-and-knn-classifier.html#black-box-convolutional-neural-networks"><i class="fa fa-check"></i><b>3.8.7</b> 3.8.6 Black-Box Convolutional Neural Networks</a></li>
<li class="chapter" data-level="3.8.8" data-path="explainable-computer-vision-with-embeddings-and-knn-classifier.html"><a href="explainable-computer-vision-with-embeddings-and-knn-classifier.html#results-18"><i class="fa fa-check"></i><b>3.8.8</b> Results</a></li>
<li class="chapter" data-level="3.8.9" data-path="explainable-computer-vision-with-embeddings-and-knn-classifier.html"><a href="explainable-computer-vision-with-embeddings-and-knn-classifier.html#conclusions-2"><i class="fa fa-check"></i><b>3.8.9</b> Conclusions</a></li>
<li class="chapter" data-level="3.8.10" data-path="explainable-computer-vision-with-embeddings-and-knn-classifier.html"><a href="explainable-computer-vision-with-embeddings-and-knn-classifier.html#bibliography"><i class="fa fa-check"></i><b>3.8.10</b> Bibliography</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="4" data-path="acknowledgements.html"><a href="acknowledgements.html"><i class="fa fa-check"></i><b>4</b> Acknowledgements</a></li>
<li class="chapter" data-level="" data-path="references-1.html"><a href="references-1.html"><i class="fa fa-check"></i>References</a></li>
<li class="divider"></li>
<li><a href="https://bookdown.org" target="_blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">ML Case Studies</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="which-neighbours-affected-house-prices-in-the-90s" class="section level2" number="3.7">
<h2><span class="header-section-number">3.7</span> Which Neighbours Affected House Prices in the ’90s?</h2>
<p><em>Authors: Hubert Baniecki, Mateusz Polakowski (Warsaw University of Technology)</em></p>
<div id="abstract-18" class="section level3" number="3.7.1">
<h3><span class="header-section-number">3.7.1</span> Abstract</h3>
<p>The house price estimation task has a long-lasting history in economics and statistics. Nowadays, both worlds unite to exploit the machine learning approach; thus, achieve the best predictive results. In the literature, there are myriad of works discussing the performance-interpretability tradeoff apparent in the modelling of real estate values. In this paper, we propose a solution to this problem, which is a highly interpretable stacked model that outperforms the black-box models. We use it to examine neighbourhood parameters affecting the median house price of the United States regions in 1990.</p>
</div>
<div id="introduction-2" class="section level3" number="3.7.2">
<h3><span class="header-section-number">3.7.2</span> Introduction</h3>
<p>Real estate value varies over numerous factors. These may be obvious like location or interior design, but also less apparent like the ethnicity and age of neighbours. Therefore, property price estimation is a demanding job that often requires a lot of experience and market knowledge. Is or was, because nowadays, Artificial Intelligence (AI) surpasses humans in this task <span class="citation">(Conway <a href="#ref-3-7-realestate-ai" role="doc-biblioref">2018</a>)</span>. Interested parties more often use tools like supervised Machine Learning (ML) models to precisely evaluate the property value and gain a competitive advantage <span class="citation">(Park and Bae <a href="#ref-3-7-realestate-ml1" role="doc-biblioref">2015</a>, @3–7–realestate–ml2, @3–7–realestate–ml3)</span>.</p>
<p>The dilemma is in blindly trusting the prediction given by so-called black-box models. These are ML algorithms that take loads of various real estate data as input and return a house price estimation without giving their reasoning. Black-box complex nature is its biggest strength and weakness at the same time. This trait regularly entails high effectiveness but does not allow for interpretation of model outputs <span class="citation">(Baldominos et al. <a href="#ref-3-7-multiple-models" role="doc-biblioref">2018</a>)</span>. Because of that, specialists interested in supporting their work with automated ML decision-making are more eager to use white-box models like linear regression or decision trees <span class="citation">(Selim <a href="#ref-3-7-wb-vs-bb" role="doc-biblioref">2009</a>)</span>. These do not achieve state-of-the-art performance efficiently, but instead, provide valuable information about the relationships present in data through model interpretation.</p>
<p>For many years houses have been popular properties; thus, they are of particular interest for ordinary people. What exact influence had the demographic characteristics of the house neighbourhood on its price in the ’90s? Although in the absence of current technology, it has been hard to answer such question years ago <span class="citation">(Din, Hoesli, and Bender <a href="#ref-3-7-history2001" role="doc-biblioref">2001</a>)</span>, now we can.</p>
<p>In this paper, we perform a case study on the actual United States Census data from 1990 <span class="citation">(<span class="citeproc-not-found" data-reference-id="3-7-housepricesdata"><strong>???</strong></span>)</span> and deliver an interpretable white-box model that estimates the median house price by the region. We present multiple approaches to this problem and choose the best model, which achieves similar performance to complex black-boxes. Finally, using its interpretable nature, we answer various questions that give a new life to this historical data.</p>
</div>
<div id="related-work-12" class="section level3" number="3.7.3">
<h3><span class="header-section-number">3.7.3</span> Related Work</h3>
<p>The use of ML in the real estate domain is a well-documented ground <span class="citation">(Conway <a href="#ref-3-7-realestate-ai" role="doc-biblioref">2018</a>)</span> and not precisely a topic of this contribution. We relate to the works that aim to use Interpretable ML techniques <span class="citation">(<span class="citeproc-not-found" data-reference-id="3-7-christophmonlar"><strong>???</strong></span>)</span> to interpret models predictions in the house price estimation problem.</p>
<p>The state-of-the-art approach to house price estimation is to combine linear and semi-log regression models with the Hedonic Pricing Method <span class="citation">(Garrod and Willis <a href="#ref-3-7-hpm1" role="doc-biblioref">1992</a>, @3–7–hpm2)</span>, which aims to determine the extent that environmental or ecosystem factors affect the price of a good. <span class="citation">(Özalp and Akinci <a href="#ref-3-7-hpm-iml" role="doc-biblioref">2017</a>)</span> deliberately seeks to interpret the outcome and provide information about the parameters that affect property value. There are also comparisons between the linear white-box and black-box models <span class="citation">(Selim <a href="#ref-3-7-wb-vs-bb" role="doc-biblioref">2009</a>, @3–7–multiple–models)</span> which showcase the performance-interpretability tradeoff <span class="citation">(Gosiewska and Biecek <a href="#ref-3-7-gosiewska-lifting" role="doc-biblioref">2020</a>)</span>.</p>
<p>Nature of the topic might entail that the data is place-specific; therefore, part of the studies focus on a single location with the use of geospatial data. The case study on London <span class="citation">(Law <a href="#ref-3-7-localarea-network" role="doc-biblioref">2017</a>)</span> links the street network community structure with house price, which takes into consideration the topology of the city. In contradiction, <span class="citation">(Heyman and Sommervoll <a href="#ref-3-7-relative-absolute" role="doc-biblioref">2019</a>)</span> uses the Oslo city data to explore the differences between the relative and absolute location attributes. Applying the data like the distance to the nearest shop and transportation is place-agnostic.</p>
<p>One of the new ideas is to utilize the location data from multiple sources in a Multi-Task Learning approach <span class="citation">(Gao et al. <a href="#ref-3-7-mlt" role="doc-biblioref">2019</a>)</span>. It also studies the relationships between the tasks, which gives an extensive insight on prediction attributions.</p>
<p>In this paper we partialy aim to enhance the use of regression decision tree models, which had been utilized to estimate the house prices based on their essential characteristics in <span class="citation">(Fan, Ong, and Koh <a href="#ref-3-7-houseprices-tree" role="doc-biblioref">2006</a>)</span>.</p>
</div>
<div id="data-3" class="section level3" number="3.7.4">
<h3><span class="header-section-number">3.7.4</span> Data</h3>
<p>For this case study we use the <em>house_8L</em> dataset crafted from the data collected in 1990 by the United States Census Bureau. Each record stands for a distinct United States state while the target value is a median house price in a given region. The variables are presented in Table <a href="which-neighbours-affected-house-prices-in-the-90s.html#tab:3-7-dataset">3.1</a>.</p>
<table class="table table-bordered" style="width: auto !important; margin-left: auto; margin-right: auto;">
<caption>
<span id="tab:3-7-dataset">TABLE 3.1: </span>Description of variables present in the house_8L dataset.
</caption>
<thead>
<tr>
<th style="text-align:center;">
Original name
</th>
<th style="text-align:center;">
New name
</th>
<th style="text-align:center;">
Description
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center;width: 10em; ">
price
</td>
<td style="text-align:center;width: 10em; font-weight: bold;">
price
</td>
<td style="text-align:center;width: 40em; background-color: white !important;">
median price of the house in the region
</td>
</tr>
<tr>
<td style="text-align:center;width: 10em; ">
P3
</td>
<td style="text-align:center;width: 10em; font-weight: bold;">
house_n
</td>
<td style="text-align:center;width: 40em; background-color: white !important;">
total number of households
</td>
</tr>
<tr>
<td style="text-align:center;width: 10em; ">
H15.1
</td>
<td style="text-align:center;width: 10em; font-weight: bold;">
avg_room_n
</td>
<td style="text-align:center;width: 40em; background-color: white !important;">
average number of rooms in an owner-occupied Housing Units
</td>
</tr>
<tr>
<td style="text-align:center;width: 10em; ">
H5.2
</td>
<td style="text-align:center;width: 10em; font-weight: bold;">
forsale_h_pct
</td>
<td style="text-align:center;width: 40em; background-color: white !important;">
percentage of vacant Housing Units which are for sale only
</td>
</tr>
<tr>
<td style="text-align:center;width: 10em; ">
H40.4
</td>
<td style="text-align:center;width: 10em; font-weight: bold;">
forsale_6mplus_h_pct
</td>
<td style="text-align:center;width: 40em; background-color: white !important;">
percentage of vacant-for-sale Housing Units vacant more then 6 months
</td>
</tr>
<tr>
<td style="text-align:center;width: 10em; ">
P11.3
</td>
<td style="text-align:center;width: 10em; font-weight: bold;">
age_25_64_pct
</td>
<td style="text-align:center;width: 40em; background-color: white !important;">
percentage of people between 25-64 years of age
</td>
</tr>
<tr>
<td style="text-align:center;width: 10em; ">
P16.2
</td>
<td style="text-align:center;width: 10em; font-weight: bold;">
family_2plus_h_pct
</td>
<td style="text-align:center;width: 40em; background-color: white !important;">
percentage of households with 2 or more persons which are family households
</td>
</tr>
<tr>
<td style="text-align:center;width: 10em; ">
P19.2
</td>
<td style="text-align:center;width: 10em; font-weight: bold;">
black_h_pct
</td>
<td style="text-align:center;width: 40em; background-color: white !important;">
percentage of households with black Householder
</td>
</tr>
<tr>
<td style="text-align:center;width: 10em; ">
P6.4
</td>
<td style="text-align:center;width: 10em; font-weight: bold;">
asian_p_pct
</td>
<td style="text-align:center;width: 40em; background-color: white !important;">
percentage of people which are of Asian or Pacific Islander race
</td>
</tr>
</tbody>
</table>
<p>Furthermore, we will apply our Metodology (Section 4) on a corresponding <em>house_16H</em> dataset, which has the same target but a different set of variables.
More correlated variables of a higher variance make it significantly harder to estimate the median house price in a given region.
Such validation will allow us to evaluate our model on a more demanding task.
The comprehensive description of used data can be found in <span class="citation">(“Census dataset” <a href="#ref-housepricesdata" role="doc-biblioref">1996</a>)</span>.</p>
</div>
<div id="methodology-18" class="section level3" number="3.7.5">
<h3><span class="header-section-number">3.7.5</span> Methodology</h3>
<p>In this section, we are going to focus on developing the best white-box model, which provides interpretability of features. Throughout this case study, we use the Mean Absolute Error (MAE) measure to evaluate the model performance, because we focus on the residuals while the mean of absolute values of residuals is the easiest to interpret.</p>
<div id="exploratory-data-analysis" class="section level4" number="3.7.5.1">
<h4><span class="header-section-number">3.7.5.1</span> Exploratory Data Analysis</h4>
<p>The main conclusions from the Exploratory Data Analysis are as follows:</p>
<ol style="list-style-type: decimal">
<li>The target value is very skewed (See Figure <a href="which-neighbours-affected-house-prices-in-the-90s.html#fig:3-7-eda">3.6</a>).</li>
<li>There are 6 percentage and 2 count variables.</li>
<li>The dataset has over 22k data points.</li>
<li>There are 46 data points with unnaturally looking target value.</li>
<li>There are no missing values.</li>
</ol>
<div class="figure" style="text-align: center"><span id="fig:3-7-eda"></span>
<img src="images/3-7-eda.png" alt="(L) Histogram of the target values. (R) Examplary variable correlation with the target." width="800" />
<p class="caption">
FIGURE 3.6: (L) Histogram of the target values. (R) Examplary variable correlation with the target.
</p>
</div>
<p>Therefore we decided that:</p>
<ol style="list-style-type: decimal">
<li>We will not transform the skewed target because this might provide less interpretability.</li>
<li>There are not many possibilities for feature engineering.</li>
<li>We can reliably split the data into train and test using 2:1 ratio.</li>
<li>We suspect that the target value of 500001 is artificially made, so we remove these outliers.</li>
</ol>
<p>Throughout this case study, we use the Mean Absolute Error (MAE) measure to evaluate the model performance, because we later focus on the residuals while the mean of absolute values of residuals is the easiest to interpret.</p>
</div>
<div id="safe" class="section level4" number="3.7.5.2">
<h4><span class="header-section-number">3.7.5.2</span> SAFE</h4>
<p>The first approach was using the SAFE <span class="citation">(Gosiewska et al. <a href="#ref-gosiewska2019safe" role="doc-biblioref">2019</a>)</span> technique to engineer new features and produce a linear regression model. We trained a well-performing black-box <code>ranger</code> <span class="citation">(Wright and Ziegler <a href="#ref-ranger" role="doc-biblioref">2017</a>)</span> model and extracted new interpretable features using its Partial Dependence Profiles <span class="citation">(Friedman <a href="#ref-pdp" role="doc-biblioref">2000</a>)</span>. Then we used these features to craft a new linear model which indeed was better than the baseline linear model by about 10%. It is worth noting that both of these linear models had a hard time succeeding because of the target skewness.</p>
</div>
<div id="divide-and-conquer" class="section level4" number="3.7.5.3">
<h4><span class="header-section-number">3.7.5.3</span> Divide-and-conquer</h4>
<p>In this section, we present the main contribution of this paper.
The divide-and-conquer idea has many computer science applications, e.g. in sorting algorithms, natural language processing, or parallel computing.
We decided to make use of its core principles in constructing the method for fitting the enhanced white-box model.
The final result is multiple tree models combined which decisions are easily interpretable.</p>
<p>The proposed algorithm presented in Figure <a href="which-neighbours-affected-house-prices-in-the-90s.html#fig:3-7-algorithm">3.7</a> is:</p>
<ol style="list-style-type: decimal">
<li>Divide the target variable with <code>k</code> middle points into <code>k+1</code> groups.</li>
<li>Fit a black-box classifier on train data which predicts the belonging to the <code>i-th</code> group.</li>
<li>Use this classifier to divide the train and test data into <code>k+1</code> train and test subsets.</li>
<li>For every <code>i-th</code> subset fit a white-box estimator of target variable on the <code>i-th</code> train data.</li>
<li>Use the <code>i-th</code> estimator to predict the outcome of the <code>i-th</code> test data.</li>
</ol>
<div class="figure" style="text-align: center"><span id="fig:3-7-algorithm"></span>
<img src="images/3-7-algorithm.png" alt="The divide-and-conquer algorithm used to construct an enhanced white-box model. (1) Divide the target variable with `k` middle points into `k+1` groups. (2) Fit a black-box classifier on train data which predicts the belonging to the `i-th` group. (3) Use this classifier to divide the train and test data into `k+1` train and test subsets. (4) For every `i-th` subset fit a white-box estimator." width="800" />
<p class="caption">
FIGURE 3.7: The divide-and-conquer algorithm used to construct an enhanced white-box model. (1) Divide the target variable with <code>k</code> middle points into <code>k+1</code> groups. (2) Fit a black-box classifier on train data which predicts the belonging to the <code>i-th</code> group. (3) Use this classifier to divide the train and test data into <code>k+1</code> train and test subsets. (4) For every <code>i-th</code> subset fit a white-box estimator.
</p>
</div>
<p>The final product is a stacked model with one classifier and <code>k+1</code> estimators. The exact models are for engineers to choose. It is worth noting that the unsupervised clustering method might be used instead of the classification model.</p>
</div>
</div>
<div id="results-17" class="section level3" number="3.7.6">
<h3><span class="header-section-number">3.7.6</span> Results</h3>
<div id="the-stacked-model" class="section level4" number="3.7.6.1">
<h4><span class="header-section-number">3.7.6.1</span> The stacked model</h4>
<p>For the house price task, we chose <code>k = 1</code>, and the middle point was arbitrary chosen as <code>100k</code>, which divides the data into two groups in about a 10:1 ratio. We used the <code>ranger</code> random forest model as a black-box classifier and the <code>rpart</code> <span class="citation">(Therneau and Atkinson <a href="#ref-rpart" role="doc-biblioref">2019</a>)</span> decision tree model as a white-box estimator.</p>
<p>The <code>ranger</code> model had default parameters with <code>mtry=3</code>. The parameters of <code>rpart</code> models were:</p>
<ul>
<li><code>maxdepth = 4</code> - low depth reassures the interpretability of the model</li>
<li><code>cp = 0.001</code> - lower complexity helps with the skewed target</li>
<li><code>minbucket = 1% of the training data</code> - more filled tree leaves adds up to higher interpretability</li>
</ul>
<p>Figure <a href="which-neighbours-affected-house-prices-in-the-90s.html#fig:3-7-tree1">3.8</a> depicts the tree that estimates cheaper houses, while Figure <a href="which-neighbours-affected-house-prices-in-the-90s.html#fig:3-7-tree2">3.9</a> presents the tree that estimates more expensive houses.</p>
<div class="figure" style="text-align: center"><span id="fig:3-7-tree1"></span>
<img src="images/3-7-tree-cheap.svg" alt="The tree that estimates cheaper houses. Part of the stacked model." width="800" />
<p class="caption">
FIGURE 3.8: The tree that estimates cheaper houses. Part of the stacked model.
</p>
</div>
<div class="figure" style="text-align: center"><span id="fig:3-7-tree2"></span>
<img src="images/3-7-tree-rich.svg" alt="The tree that estimates more expensive houses. Part of the stacked model." width="800" />
<p class="caption">
FIGURE 3.9: The tree that estimates more expensive houses. Part of the stacked model.
</p>
</div>
<p>Interpreting the stacked model presented in Figures <a href="which-neighbours-affected-house-prices-in-the-90s.html#fig:3-7-tree1">3.8</a> &amp; <a href="which-neighbours-affected-house-prices-in-the-90s.html#fig:3-7-tree2">3.9</a> leads to multiple conclusions. Firstly, we can observe the noticeable impact of features like the total number of households or the average number of rooms on the median price of the house in the region, which is compliant with basic intuitions. It is also evident that the bigger percentage of people between 25-64 years of age the higher the prices.</p>
<p>Finally, we can observe the impact of critical features. The percentage of people which are of Asian or Pacific Islander race divides the prices in an opposing direction to the percentage of households with black Householder. The corresponding tree splits showcase which neighbours, and in what manner, affected house prices in the ’90s. Whether it is a correlation or causality is a valid debate that could be further investigated.</p>
</div>
<div id="comparison-of-the-residuals" class="section level4" number="3.7.6.2">
<h4><span class="header-section-number">3.7.6.2</span> Comparison of the residuals</h4>
<p>In this section, we compare our stacked model with baseline <code>ranger</code> and <code>rpart</code> models, respectively referred to as black-box and white-box. Our solution achieves competitive performance with interpretable features.</p>
<p>The main idea behind the divide-and-conquer technique was to minimize the maximum value of the absolute residuals, which reassures that no significant errors will happen. Such an approach may inevitably lead to minimizing the sum of the absolute residual values (MAE). In Figure (fig:3-7-boxplot), we can see that the targets mentioned above were indeed met. The stacked model not only has the lowest maximum error value but also has the best performance on average, as the red dot highlights the MAE score.</p>
<div class="figure" style="text-align: center"><span id="fig:3-7-boxplot"></span>
<img src="images/3-7-boxplot.png" alt="Boxplots of residuals for the stacked model compared to black-box and white-box models. The plot is divided for cheaper and more expensive houses. The red dot highlights the MAE score." width="800" />
<p class="caption">
FIGURE 3.10: Boxplots of residuals for the stacked model compared to black-box and white-box models. The plot is divided for cheaper and more expensive houses. The red dot highlights the MAE score.
</p>
</div>
<p>Figure (fig:3-7-density) presents a more in-depth analysis of model residuals. In the top, we can observe that the black-box model has the lowest absolute residual mode (tip of the distribution), but the stacked model lays more in the centre (base of the distribution), which leads to more even spread of residuals. In the bottom, we can observe that the black-box model tends to undervalue house prices, while our model overestimates them. Looking at the height of the tip of the distribution and its shape, we can conclude that the stacked model provides more reliable estimations.</p>
<div class="figure" style="text-align: center"><span id="fig:3-7-density"></span>
<img src="images/3-7-density.png" alt="Density of residuals for the stacked model compared to black-box and white-box models. The plot is divided for cheaper and more expensive houses." width="800" />
<p class="caption">
FIGURE 3.11: Density of residuals for the stacked model compared to black-box and white-box models. The plot is divided for cheaper and more expensive houses.
</p>
</div>
</div>
<div id="comparison-of-the-scores" class="section level4" number="3.7.6.3">
<h4><span class="header-section-number">3.7.6.3</span> Comparison of the scores</h4>
<p>Finally, we present the comparison of MAE scores for all of the used models in this case study in Table <a href="which-neighbours-affected-house-prices-in-the-90s.html#tab:3-7-table-results">3.2</a>. There are two tasks with different variables, complexity and correlations. We calculate the scores on the test subsets.</p>
<p>We can see that the linear models performed the worse, although the SAFE approach noticeably lowered the MAE. Then there is a decision tree which performed better but not so on the more laborious task. Both of the black-box models did a far better job at house price estimation than interpretable models. Finally, our stacked model is a champion with the best performance on both of the tasks.</p>
<table class="table table-bordered" style="width: auto !important; margin-left: auto; margin-right: auto;">
<caption>
<span id="tab:3-7-table-results">TABLE 3.2: </span>Comparison of the MAE score for all of the used models on test datasets. Green colour highlights white-box models, while the red colour is for black-box models.
</caption>
<thead>
<tr>
<th style="border-bottom:hidden" colspan="1">
</th>
<th style="border-bottom:hidden; padding-bottom:0; padding-left:3px;padding-right:3px;text-align: center; " colspan="2">
<div style="border-bottom: 1px solid #ddd; padding-bottom: 5px; ">
Dataset (test)
</div>
</th>
</tr>
<tr>
<th style="text-align:center;">
Model
</th>
<th style="text-align:center;">
house_8L
</th>
<th style="text-align:center;">
house_16H
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center;width: 20em; font-weight: bold;color: black !important;background-color: #8bdcbe !important;">
linear model
</td>
<td style="text-align:center;width: 10em; color: black !important;background-color: #8bdcbe !important;">
23.1k
</td>
<td style="text-align:center;width: 10em; color: black !important;background-color: #8bdcbe !important;">
24.1k
</td>
</tr>
<tr>
<td style="text-align:center;width: 20em; font-weight: bold;color: black !important;background-color: #8bdcbe !important;">
SAFE on ranger
</td>
<td style="text-align:center;width: 10em; color: black !important;background-color: #8bdcbe !important;">
21.4k
</td>
<td style="text-align:center;width: 10em; color: black !important;background-color: #8bdcbe !important;">
22.6k
</td>
</tr>
<tr>
<td style="text-align:center;width: 20em; font-weight: bold;color: black !important;background-color: #8bdcbe !important;">
rpart
</td>
<td style="text-align:center;width: 10em; color: black !important;background-color: #8bdcbe !important;">
19.2k
</td>
<td style="text-align:center;width: 10em; color: black !important;background-color: #8bdcbe !important;">
22.1k
</td>
</tr>
<tr>
<td style="text-align:center;width: 20em; font-weight: bold;color: black !important;background-color: #f05a71 !important;">
xgboost
</td>
<td style="text-align:center;width: 10em; color: black !important;background-color: #f05a71 !important;">
16k
</td>
<td style="text-align:center;width: 10em; color: black !important;background-color: #f05a71 !important;">
16.5k
</td>
</tr>
<tr>
<td style="text-align:center;width: 20em; font-weight: bold;color: black !important;background-color: #f05a71 !important;">
ranger
</td>
<td style="text-align:center;width: 10em; color: black !important;background-color: #f05a71 !important;">
14.8k
</td>
<td style="text-align:center;width: 10em; color: black !important;background-color: #f05a71 !important;">
15.6k
</td>
</tr>
<tr>
<td style="text-align:center;width: 20em; font-weight: bold;color: black !important;background-color: #8bdcbe !important;">
stacked model
</td>
<td style="text-align:center;width: 10em; color: black !important;background-color: #8bdcbe !important;">
14.6k
</td>
<td style="text-align:center;width: 10em; color: black !important;background-color: #8bdcbe !important;">
15.3k
</td>
</tr>
</tbody>
</table>
</div>
</div>
<div id="conclusions-1" class="section level3" number="3.7.7">
<h3><span class="header-section-number">3.7.7</span> Conclusions</h3>
<p><strong>TODO: Conclusions</strong></p>

</div>
</div>
<h3>References</h3>
<div id="refs" class="references">
<div id="ref-3-7-multiple-models">
<p>Baldominos, Alejandro, Iván Blanco, Antonio Moreno, Rubén Iturrarte, Óscar Bernárdez, and Carlos Afonso. 2018. “Identifying Real Estate Opportunities Using Machine Learning.” <em>Applied Sciences</em> 8 (November): 2321. <a href="https://doi.org/10.3390/app8112321">https://doi.org/10.3390/app8112321</a>.</p>
</div>
<div id="ref-housepricesdata">
<p>“Census dataset.” 1996. <a href="http://www.cs.toronto.edu/~delve/data/census-house/censusDetail.html">http://www.cs.toronto.edu/~delve/data/census-house/censusDetail.html</a>.</p>
</div>
<div id="ref-3-7-realestate-ai">
<p>Conway, Jennifer. 2018. “Artificial Intelligence and Machine Learning : Current Applications in Real Estate.” PhD thesis. <a href="https://dspace.mit.edu/bitstream/handle/1721.1/120609/1088413444-MIT.pdf">https://dspace.mit.edu/bitstream/handle/1721.1/120609/1088413444-MIT.pdf</a>.</p>
</div>
<div id="ref-3-7-history2001">
<p>Din, Allan, Martin Hoesli, and André Bender. 2001. “Environmental Variables and Real Estate Prices.” <em>Urban Studies</em> 38 (February). <a href="https://doi.org/10.1080/00420980120080899">https://doi.org/10.1080/00420980120080899</a>.</p>
</div>
<div id="ref-3-7-houseprices-tree">
<p>Fan, Gang-Zhi, Seow Eng Ong, and Hian Koh. 2006. “Determinants of House Price: A Decision Tree Approach.” <em>Urban Studies</em> 43 (November): 2301–16. <a href="https://doi.org/10.1080/00420980600990928">https://doi.org/10.1080/00420980600990928</a>.</p>
</div>
<div id="ref-pdp">
<p>Friedman, Jerome. 2000. “Greedy Function Approximation: A Gradient Boosting Machine.” <em>The Annals of Statistics</em> 29 (November). <a href="https://doi.org/10.1214/aos/1013203451">https://doi.org/10.1214/aos/1013203451</a>.</p>
</div>
<div id="ref-3-7-mlt">
<p>Gao, Guangliang, Zhifeng Bao, Jie Cao, A. Qin, Timos Sellis, Fellow, IEEE, and Zhiang Wu. 2019. “Location-Centered House Price Prediction: A Multi-Task Learning Approach,” January. <a href="https://arxiv.org/abs/1901.01774">https://arxiv.org/abs/1901.01774</a>.</p>
</div>
<div id="ref-3-7-hpm1">
<p>Garrod, Guy D, and Kenneth G Willis. 1992. “Valuing Goods’ Characteristics: An Application of the Hedonic Price Method to Environmental Attributes.” <em>Journal of Environmental Management</em> 34 (1): 59–76.</p>
</div>
<div id="ref-3-7-gosiewska-lifting">
<p>Gosiewska, Alicja, and Przemyslaw Biecek. 2020. “Lifting Interpretability-Performance Trade-off via Automated Feature Engineering.” <a href="https://arxiv.org/abs/2002.04267">https://arxiv.org/abs/2002.04267</a>.</p>
</div>
<div id="ref-gosiewska2019safe">
<p>Gosiewska, Alicja, Aleksandra Gacek, Piotr Lubon, and Przemyslaw Biecek. 2019. “SAFE Ml: Surrogate Assisted Feature Extraction for Model Learning.” <a href="http://arxiv.org/abs/1902.11035">http://arxiv.org/abs/1902.11035</a>.</p>
</div>
<div id="ref-3-7-relative-absolute">
<p>Heyman, Axel, and Dag Sommervoll. 2019. “House Prices and Relative Location.” <em>Cities</em> 95 (September): 102373. <a href="https://doi.org/10.1016/j.cities.2019.06.004">https://doi.org/10.1016/j.cities.2019.06.004</a>.</p>
</div>
<div id="ref-3-7-localarea-network">
<p>Law, Stephen. 2017. “Defining Street-Based Local Area and Measuring Its Effect on House Price Using a Hedonic Price Approach: The Case Study of Metropolitan London.” <em>Cities</em> 60 (February): 166–79. <a href="https://doi.org/10.1016/j.cities.2016.08.008">https://doi.org/10.1016/j.cities.2016.08.008</a>.</p>
</div>
<div id="ref-3-7-hpm-iml">
<p>Özalp, Ayşe, and Halil Akinci. 2017. “The Use of Hedonic Pricing Method to Determine the Parameters Affecting Residential Real Estate Prices.” <em>Arabian Journal of Geosciences</em> 10 (December). <a href="https://doi.org/10.1007/s12517-017-3331-3">https://doi.org/10.1007/s12517-017-3331-3</a>.</p>
</div>
<div id="ref-3-7-realestate-ml1">
<p>Park, Byeonghwa, and Jae Bae. 2015. “Using machine learning algorithms for housing price prediction: The case of Fairfax County, Virginia housing data.” <em>Expert Systems with Applications</em> 42 (April). <a href="https://doi.org/10.1016/j.eswa.2014.11.040">https://doi.org/10.1016/j.eswa.2014.11.040</a>.</p>
</div>
<div id="ref-3-7-wb-vs-bb">
<p>Selim, Hasan. 2009. “Determinants of House Prices in Turkey: Hedonic Regression Versus Artificial Neural Network.” <em>Expert Syst. Appl.</em> 36 (March): 2843–52. <a href="https://doi.org/10.1016/j.eswa.2008.01.044">https://doi.org/10.1016/j.eswa.2008.01.044</a>.</p>
</div>
<div id="ref-rpart">
<p>Therneau, Terry, and Beth Atkinson. 2019. <em>Rpart: Recursive Partitioning and Regression Trees</em>. <a href="https://CRAN.R-project.org/package=rpart">https://CRAN.R-project.org/package=rpart</a>.</p>
</div>
<div id="ref-ranger">
<p>Wright, Marvin N., and Andreas Ziegler. 2017. “ranger: A Fast Implementation of Random Forests for High Dimensional Data in C++ and R.” <em>Journal of Statistical Software</em> 77 (1): 1–17. <a href="https://doi.org/10.18637/jss.v077.i01">https://doi.org/10.18637/jss.v077.i01</a>.</p>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="surpassing-black-box-models-performance-on-unbalanced-data-with-an-interpretable-one-using-advanced-feature-engineering.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="explainable-computer-vision-with-embeddings-and-knn-classifier.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook/js/app.min.js"></script>
<script src="libs/gitbook/js/lunr.js"></script>
<script src="libs/gitbook/js/clipboard.min.js"></script>
<script src="libs/gitbook/js/plugin-search.js"></script>
<script src="libs/gitbook/js/plugin-sharing.js"></script>
<script src="libs/gitbook/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook/js/plugin-bookdown.js"></script>
<script src="libs/gitbook/js/jquery.highlight.js"></script>
<script src="libs/gitbook/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": true,
"facebook": false,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/mini-pw/2020L-WB-Book/edit/master/3-7-house-prices.Rmd",
"text": "Edit"
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["book.pdf", "book.epub"],
"toc": {
"collapse": "section"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
